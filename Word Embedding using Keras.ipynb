{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences #padding is used in NLP due to the mixed sizes of sentences\n",
    "from keras.preprocessing.text import one_hot #one hot encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding #this is for word embedding. \n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining docs\n",
    "\n",
    "docs=['Hi, how are you doing?',\n",
    "     'Hey,nice to see you.',\n",
    "     'Hi,long time no see',\n",
    "     'Hey, how was your day?',\n",
    "     'Bye, I had a long day.',\n",
    "     'Goodbye, I am leaving.',\n",
    "     'Bye, take care.',\n",
    "     'Bye Bye, see you tomorrow.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=10000 #A set of unique words in the text corpus is referred to as vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs= [one_hot(d,vocab_size) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6846, 2720, 9702, 8042, 3406], [3935, 6155, 1546, 5460, 8042], [6846, 4691, 3743, 1527, 5460], [3935, 2720, 1115, 249, 289], [4598, 1765, 9762, 2183, 4691, 289], [6082, 1765, 7351, 8618], [4598, 5352, 4694], [4598, 4598, 5460, 8042, 8513]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_leng=8\n",
    "padded_docs=pad_sequences(encoded_docs,maxlen=max_leng,padding='post') #padding can be done 'pre' or 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6846 2720 9702 8042 3406    0    0    0]\n",
      " [3935 6155 1546 5460 8042    0    0    0]\n",
      " [6846 4691 3743 1527 5460    0    0    0]\n",
      " [3935 2720 1115  249  289    0    0    0]\n",
      " [4598 1765 9762 2183 4691  289    0    0]\n",
      " [6082 1765 7351 8618    0    0    0    0]\n",
      " [4598 5352 4694    0    0    0    0    0]\n",
      " [4598 4598 5460 8042 8513    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 8, 8)              80000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 80,065\n",
      "Trainable params: 80,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_leng))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4944323 ]\n",
      " [0.4959454 ]\n",
      " [0.4851119 ]\n",
      " [0.50829816]\n",
      " [0.5011931 ]\n",
      " [0.48577785]\n",
      " [0.48820183]\n",
      " [0.5053238 ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(padded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,10,input_length=max_leng))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.04537784  0.0083411   0.03081994 -0.0478183   0.04960659\n",
      "   -0.01725149 -0.03183778  0.02988802 -0.00287731 -0.00790299]\n",
      "  [ 0.01889605  0.02627499  0.02581621  0.02746418 -0.01059824\n",
      "    0.04166779 -0.01684181  0.04155577  0.02775759  0.04204216]\n",
      "  [-0.04900867 -0.0180701   0.0271724   0.03542208 -0.02660426\n",
      "    0.0190523   0.03948892  0.0254466  -0.03122598 -0.00922215]\n",
      "  [-0.034073    0.03794849 -0.00715496  0.01529953  0.03397324\n",
      "   -0.01706555 -0.0359123   0.01282148  0.01515477 -0.02209485]\n",
      "  [ 0.04826702  0.03211614  0.01470405 -0.03259025  0.00767369\n",
      "    0.00182099 -0.01983203 -0.0235298   0.00010216 -0.04800428]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]]\n",
      "\n",
      " [[ 0.03496658 -0.00999427 -0.00429543 -0.02451773 -0.03346428\n",
      "    0.04903989  0.03676962 -0.02241477  0.04242567  0.01220562]\n",
      "  [-0.02721024 -0.02653215  0.02597079 -0.00829963  0.04284603\n",
      "    0.01434204 -0.03464242  0.02507767  0.02600538 -0.04762579]\n",
      "  [-0.04186489  0.01036184 -0.01889484 -0.01301125  0.01128088\n",
      "   -0.0068952   0.00706454 -0.01131033  0.00081789 -0.00243577]\n",
      "  [-0.0457545  -0.02071297 -0.0120519   0.01055165  0.03451623\n",
      "    0.02880662 -0.01787389  0.01493809 -0.02187965 -0.00124843]\n",
      "  [-0.034073    0.03794849 -0.00715496  0.01529953  0.03397324\n",
      "   -0.01706555 -0.0359123   0.01282148  0.01515477 -0.02209485]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]]\n",
      "\n",
      " [[ 0.04537784  0.0083411   0.03081994 -0.0478183   0.04960659\n",
      "   -0.01725149 -0.03183778  0.02988802 -0.00287731 -0.00790299]\n",
      "  [-0.03340223  0.01859372  0.04016512 -0.02273467  0.00129992\n",
      "   -0.04054402  0.03093234  0.02715811  0.04013467 -0.04386281]\n",
      "  [ 0.00418366 -0.03718366 -0.01985871 -0.03644748  0.00535534\n",
      "   -0.03470069 -0.02930473 -0.02941763 -0.04378688 -0.047757  ]\n",
      "  [-0.03417394 -0.02065337 -0.0175478   0.04850364  0.02797122\n",
      "   -0.01167948  0.04273898 -0.01952217 -0.02696567  0.0240477 ]\n",
      "  [-0.0457545  -0.02071297 -0.0120519   0.01055165  0.03451623\n",
      "    0.02880662 -0.01787389  0.01493809 -0.02187965 -0.00124843]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]]\n",
      "\n",
      " [[ 0.03496658 -0.00999427 -0.00429543 -0.02451773 -0.03346428\n",
      "    0.04903989  0.03676962 -0.02241477  0.04242567  0.01220562]\n",
      "  [ 0.01889605  0.02627499  0.02581621  0.02746418 -0.01059824\n",
      "    0.04166779 -0.01684181  0.04155577  0.02775759  0.04204216]\n",
      "  [ 0.03720833 -0.0225414  -0.03005633  0.04201733  0.01265469\n",
      "    0.01312859  0.01658435 -0.0123997  -0.03048937 -0.02418795]\n",
      "  [-0.01751219 -0.01278397  0.0377993   0.03991184  0.00518487\n",
      "   -0.04483715  0.01049263  0.03001272 -0.02914705 -0.03224621]\n",
      "  [ 0.00423117 -0.00462425  0.03138504  0.00587863 -0.04666399\n",
      "   -0.02709204  0.01540771  0.02742399  0.04610893  0.00030435]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]]\n",
      "\n",
      " [[ 0.01535619 -0.00982605  0.03568072 -0.00971141  0.0126614\n",
      "   -0.00270136 -0.00033183 -0.00841216 -0.02711142 -0.04016186]\n",
      "  [-0.0383283  -0.00120772  0.01838015 -0.00865529 -0.01628504\n",
      "    0.03706041 -0.02755927 -0.01771151  0.03823134 -0.01549519]\n",
      "  [ 0.0479408  -0.00482155  0.04081594  0.03426626 -0.00716438\n",
      "    0.0205901  -0.03948498  0.00076375 -0.0091037   0.00532919]\n",
      "  [ 0.01702077 -0.00532252 -0.00852557 -0.04001032  0.02031596\n",
      "    0.03087145  0.01788199  0.02097297  0.01684985  0.00619566]\n",
      "  [-0.03340223  0.01859372  0.04016512 -0.02273467  0.00129992\n",
      "   -0.04054402  0.03093234  0.02715811  0.04013467 -0.04386281]\n",
      "  [ 0.00423117 -0.00462425  0.03138504  0.00587863 -0.04666399\n",
      "   -0.02709204  0.01540771  0.02742399  0.04610893  0.00030435]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]]\n",
      "\n",
      " [[-0.01744536  0.02343899 -0.02325041 -0.00318445 -0.01759306\n",
      "   -0.02654054 -0.00651865  0.02205329  0.01961983 -0.03425185]\n",
      "  [-0.0383283  -0.00120772  0.01838015 -0.00865529 -0.01628504\n",
      "    0.03706041 -0.02755927 -0.01771151  0.03823134 -0.01549519]\n",
      "  [ 0.00527772  0.04230814 -0.00217867  0.03058073  0.01415838\n",
      "    0.02893385  0.04577163  0.0193064   0.02495432 -0.03550353]\n",
      "  [-0.01385858  0.03239668 -0.00961382 -0.02483064  0.02186198\n",
      "   -0.04191749  0.04522317  0.00795595  0.03150934  0.04830528]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]]\n",
      "\n",
      " [[ 0.01535619 -0.00982605  0.03568072 -0.00971141  0.0126614\n",
      "   -0.00270136 -0.00033183 -0.00841216 -0.02711142 -0.04016186]\n",
      "  [ 0.01016412  0.01471336  0.0312672  -0.04494299  0.02346102\n",
      "    0.01024292 -0.01335298 -0.03349318  0.04341559 -0.02056216]\n",
      "  [-0.03457548 -0.02826026 -0.0120538  -0.00785699  0.04287365\n",
      "    0.00126388 -0.02728413  0.04691979  0.03284737  0.04138476]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]]\n",
      "\n",
      " [[ 0.01535619 -0.00982605  0.03568072 -0.00971141  0.0126614\n",
      "   -0.00270136 -0.00033183 -0.00841216 -0.02711142 -0.04016186]\n",
      "  [ 0.01535619 -0.00982605  0.03568072 -0.00971141  0.0126614\n",
      "   -0.00270136 -0.00033183 -0.00841216 -0.02711142 -0.04016186]\n",
      "  [-0.0457545  -0.02071297 -0.0120519   0.01055165  0.03451623\n",
      "    0.02880662 -0.01787389  0.01493809 -0.02187965 -0.00124843]\n",
      "  [-0.034073    0.03794849 -0.00715496  0.01529953  0.03397324\n",
      "   -0.01706555 -0.0359123   0.01282148  0.01515477 -0.02209485]\n",
      "  [-0.00254619  0.03398024  0.01252915 -0.04117378 -0.04503451\n",
      "    0.03230003  0.03062944 -0.04637673  0.03637027 -0.01259892]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]\n",
      "  [ 0.04085568 -0.03139321  0.01087933 -0.00090396  0.02564124\n",
      "    0.0295238   0.03863974  0.01339442  0.01237983 -0.01873071]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(padded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
